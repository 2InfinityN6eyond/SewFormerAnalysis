{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze SMPLH posing in SewFormer\n",
    "- Reference\n",
    "    - SewFactory/packages/mayaqltools/fbx_animation.py\n",
    "    - SewFactory/packages/mayaqltools/playblast.py\n",
    "    - Sewformer/data/human_body_prior/body_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "sys.path.append(os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "from glob import glob\n",
    "import math\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import trimesh\n",
    "\n",
    "import torch\n",
    "\n",
    "from ANALYSIS.analysis_utils import (\n",
    "    plot_panel_info,\n",
    "    visualize_meshes_plotly,\n",
    "    filter_segmentation_map,\n",
    "    filter_segmentation_map_clusters,\n",
    "    is_clockwise,\n",
    ")\n",
    "\n",
    "from env_constants import SEWFORMER_PROJ_ROOT, DATASET_ROOT, PYGARMENT_ROOT\n",
    "\n",
    "sys.path.append(PYGARMENT_ROOT)\n",
    "\n",
    "import pygarment as pyg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "garment_df = pd.read_csv(\"garment_df_20250215_165422.csv\")\n",
    "\n",
    "filtered_combination_name_list = np.unique(garment_df[\n",
    "    garment_df[\"mesh_filter_failed\"] == False\n",
    "][\"matching_combination_name\"]).tolist()\n",
    "\n",
    "filtered_combination_path_list = list(map(\n",
    "    lambda x : os.path.join(DATASET_ROOT, 'sewfactory', x),\n",
    "    filtered_combination_name_list\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_name = (\n",
    "    'Pelvis', 'L_Hip', 'R_Hip', 'Torso', 'L_Knee', 'R_Knee',\n",
    "    'Spine', 'L_Ankle', 'R_Ankle', 'Chest', 'L_Toe', 'R_Toe',\n",
    "    'Neck', 'L_Thorax', 'R_Thorax', 'Head', 'L_Shoulder', 'R_Shoulder',\n",
    "    'L_Elbow', 'R_Elbow', 'L_Wrist', 'R_Wrist', 'L_Hand', 'R_Hand', 'Nose',\n",
    "    'L_Eye', 'R_Eye', 'L_Ear', 'R_Ear', 'Head_top'\n",
    ")\n",
    "skeleton = (\n",
    "    (0,1), (1,4), (4,7), (7,10), (0,2), (2,5), (5,8), (8,11), (0,3), (3,6), (6,9),\n",
    "    (9,14), (14,17), (17,19), (19, 21), (21,23), (9,13), (13,16), (16,18), (18,20),\n",
    "    (20,22), (9,12), (12,24), (24,15), (24,25), (24,26), (25,27), (26,28), (24,29)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"joints_mat_path\": \"meta_infos/fbx_metas/joints_mat_SMPLH.npz\",\n",
    "    \"body_file\": \"\",\n",
    "    \"texture_file\": \"examples/skin_textures\",\n",
    "    \"pose_file\": \"\",\n",
    "    \"animated\": False,\n",
    "    \"num_frames\": 4,\n",
    "    \"export_log\": False,\n",
    "    \"export_folder\": \"\",\n",
    "    \"extend_time_stamp\": [\n",
    "        -150,\n",
    "        -200\n",
    "    ],\n",
    "    \"rekey\": True,\n",
    "    \"rekey_stamp\": -120,\n",
    "    \"export_final\": True,\n",
    "    \"sim_fist_anime\": \"meta_infos/fbx_metas/ani_figures.json\",\n",
    "    \"texture_color\": [\n",
    "        0.838,\n",
    "        0.720,\n",
    "        0.658\n",
    "        \n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'maya'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmaya\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cmds\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpymel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpm\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Other dependencies\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'maya'"
     ]
    }
   ],
   "source": [
    "from maya import cmds\n",
    "\n",
    "import pymel.core as pm\n",
    "\n",
    "# Other dependencies\n",
    "import numpy as np import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def amass_to_pose(src_path, save_path,save_path1):\n",
    "    bdata = np.load(src_path, allow_pickle=True)\n",
    "    fps = 0\n",
    "    try:\n",
    "        fps = bdata['mocap_framerate']\n",
    "        frame_number = bdata['trans'].shape[0]\n",
    "    except:\n",
    "#         print(list(bdata.keys()))\n",
    "        return fps\n",
    "    \n",
    "    fId = 0 # frame id of the mocap sequence\n",
    "    pose_seq = []\n",
    "    vertex_seq = []\n",
    "    if bdata['gender'] == 'male':\n",
    "        bm = male_bm\n",
    "    else:\n",
    "        bm = female_bm\n",
    "    down_sample = int(fps / ex_fps)\n",
    "#     print(frame_number)\n",
    "#     print(fps)\n",
    "    root_data=0\n",
    "    with torch.no_grad():\n",
    "        for fId in range(0, frame_number, down_sample):\n",
    "            root_orient = torch.Tensor(bdata['poses'][fId:fId+1, :3]).to(comp_device) # controls the global root orientation\n",
    "            #tt_test=root_orient[0][2].detach().clone()\n",
    "            if fId==0:\n",
    "                root_data=root_orient\n",
    "            root_orient=root_orient-root_data\n",
    "            #root_orient[0][1]=tt_test\n",
    "            pose_body = torch.Tensor(bdata['poses'][fId:fId+1, 3:66]).to(comp_device) # controls the body\n",
    "            pose_hand = torch.Tensor(bdata['poses'][fId:fId+1, 66:]).to(comp_device) # controls the finger articulation\n",
    "            betas = torch.Tensor(bdata['betas'][:10][np.newaxis]).to(comp_device) # controls the body shape\n",
    "\n",
    "            #trans = torch.Tensor(bdata['trans'][fId:fId+1]).to(comp_device)    \n",
    "            body = bm(pose_body=pose_body, pose_hand=pose_hand, betas=betas, root_orient=root_orient)\n",
    "            joint_loc = body.Jtr[0] #+ trans\n",
    "            vertex=body.v[0]\n",
    "            pose_seq.append(joint_loc.unsqueeze(0))\n",
    "            vertex_seq.append(vertex.unsqueeze(0))\n",
    "    pose_seq = torch.cat(pose_seq, dim=0)\n",
    "    vertex_seq = torch.cat(vertex_seq, dim=0).detach().cpu().numpy()\n",
    "    \n",
    "    pose_seq_np = pose_seq.detach().cpu().numpy()\n",
    "    np.save(save_path, pose_seq_np)\n",
    "    np.save(save_path1,vertex_seq)\n",
    "    return fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
